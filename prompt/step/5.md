# Step 5: Helm Installation of Redis Cluster, RabbitMQ Message Broker, and Vector Database

## Overview
Deploy high-availability Redis cluster, RabbitMQ message broker, and vector database (ChromaDB) using Helm charts with enterprise-grade configurations. This step establishes the core data layer infrastructure for caching, messaging, and AI vector operations that will support all OfferKiller microservices.

## Prerequisites Checklist
Before starting, ensure you have:
- [ ] Step 1 completed (Docker environment running on Linux VM)
- [ ] Step 2 completed (Git monorepo structure initialized on Windows)
- [ ] Step 3 completed (GitHub Actions CI/CD pipeline setup)
- [ ] Step 4 completed (Kubernetes foundational platform services)
- [ ] Linux VM with at least 16GB RAM and 100GB disk space
- [ ] Kubernetes cluster running with foundational services deployed
- [ ] Helm package manager installed (version 3.10+)
- [ ] kubectl CLI tool configured and working
- [ ] Nacos service registry operational
- [ ] Istio service mesh deployed and functional

## What We'll Create
```
infrastructure/helm/
├── charts/                           # Custom Helm charts
│   ├── redis-cluster/               # Redis HA cluster chart
│   │   ├── Chart.yaml               # Chart metadata
│   │   ├── values.yaml              # Default values
│   │   └── templates/               # Kubernetes manifests
│   │       ├── configmap.yaml       # Redis configuration
│   │       ├── service.yaml         # Service definitions
│   │       ├── statefulset.yaml     # Redis nodes
│   │       ├── sentinel.yaml        # Redis Sentinel
│   │       └── pdb.yaml             # Pod disruption budget
│   ├── rabbitmq-ha/                 # RabbitMQ HA cluster chart
│   │   ├── Chart.yaml               # Chart metadata
│   │   ├── values.yaml              # Default values
│   │   └── templates/               # Kubernetes manifests
│   │       ├── configmap.yaml       # RabbitMQ configuration
│   │       ├── service.yaml         # Service definitions
│   │       ├── statefulset.yaml     # RabbitMQ nodes
│   │       ├── secret.yaml          # Credentials
│   │       └── pdb.yaml             # Pod disruption budget
│   └── vector-database/             # ChromaDB HA cluster chart
│       ├── Chart.yaml               # Chart metadata
│       ├── values.yaml              # Default values
│       └── templates/               # Kubernetes manifests
│           ├── deployment.yaml      # ChromaDB deployment
│           ├── service.yaml         # Service definitions
│           ├── pvc.yaml             # Persistent storage
│           └── configmap.yaml       # Configuration
├── values/                          # Environment-specific values
│   ├── development/                 # Development environment
│   │   ├── redis-cluster.yaml       # Redis dev config
│   │   ├── rabbitmq-ha.yaml         # RabbitMQ dev config
│   │   └── vector-database.yaml     # Vector DB dev config
│   ├── staging/                     # Staging environment
│   │   ├── redis-cluster.yaml       # Redis staging config
│   │   ├── rabbitmq-ha.yaml         # RabbitMQ staging config
│   │   └── vector-database.yaml     # Vector DB staging config
│   └── production/                  # Production environment
│       ├── redis-cluster.yaml       # Redis prod config
│       ├── rabbitmq-ha.yaml         # RabbitMQ prod config
│       └── vector-database.yaml     # Vector DB prod config
└── scripts/                         # Deployment automation
    ├── deploy-data-layer.ps1        # Windows deployment script
    ├── deploy-data-layer.sh         # Linux deployment script
    ├── backup-restore.sh            # Backup and restore procedures
    └── monitoring-setup.sh          # Monitoring configuration
```

## Platform Architecture
```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Data Layer Infrastructure                          │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────────────┐  │
│  │  Redis Cluster  │  │ RabbitMQ Cluster│  │    Vector Database          │  │
│  │                 │  │                 │  │                             │  │
│  │ ┌─────┐ ┌─────┐ │  │ ┌─────┐ ┌─────┐ │  │ ┌─────────┐ ┌─────────────┐ │  │
│  │ │Redis│ │Redis│ │  │ │RMQ-1│ │RMQ-2│ │  │ │ChromaDB │ │ Qdrant      │ │  │
│  │ │ M/S │ │ M/S │ │  │ │     │ │     │ │  │ │Collection│ │ Collection  │ │  │
│  │ └─────┘ └─────┘ │  │ └─────┘ └─────┘ │  │ └─────────┘ └─────────────┘ │  │
│  │ ┌─────┐ ┌─────┐ │  │ ┌─────┐         │  │ ┌─────────┐ ┌─────────────┐ │  │
│  │ │Redis│ │Senti│ │  │ │RMQ-3│         │  │ │ Volume  │ │ Backup      │ │  │
│  │ │ M/S │ │ nel │ │  │ │     │         │  │ │ Storage │ │ Storage     │ │  │
│  │ └─────┘ └─────┘ │  │ └─────┘         │  │ └─────────┘ └─────────────┘ │  │
│  └─────────────────┘  └─────────────────┘  └─────────────────────────────┘  │
│           │                     │                         │                │
│           └─────────────────────┼─────────────────────────┘                │
│                                 │                                          │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                      Service Integration Layer                      │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌───────────┐  │   │
│  │  │Cache Service│  │Queue Service│  │Vector Service│  │Monitoring │  │   │
│  │  │(Session,    │  │(Events,     │  │(Embeddings, │  │(Metrics,  │  │   │
│  │  │ Temp Data)  │  │ Async Jobs) │  │ Similarity) │  │ Alerts)   │  │   │
│  │  └─────────────┘  └─────────────┘  └─────────────┘  └───────────┘  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Step-by-Step Implementation

### 5.1 Windows: Create Helm Chart Structures

**Navigate to your project directory and create the Helm chart structures:**

#### 5.1.1 Create Redis Cluster Helm Chart

**Create file: `E:\OfferKiller\infrastructure\helm\charts\redis-cluster\Chart.yaml`**

```yaml
apiVersion: v2
name: redis-cluster
description: High-availability Redis cluster for OfferKiller
type: application
version: 1.0.0
appVersion: "7.2.0"
keywords:
  - redis
  - cache
  - database
  - nosql
home: https://redis.io/
sources:
  - https://github.com/redis/redis
maintainers:
  - name: OfferKiller Team
    email: devops@offerkiller.com
dependencies:
  - name: common
    repository: https://charts.bitnami.com/bitnami
    version: 2.x.x
annotations:
  category: Database
  licenses: BSD-3-Clause
```

**Create file: `E:\OfferKiller\infrastructure\helm\charts\redis-cluster\values.yaml`**

```yaml
# Redis Cluster Configuration
redis:
  image:
    registry: docker.io
    repository: redis
    tag: "7.2.0-alpine"
    pullPolicy: IfNotPresent
  
  # Cluster configuration
  cluster:
    enabled: true
    nodes: 6
    replicas: 1
    
  # Authentication
  auth:
    enabled: true
    password: "redis123change"
    existingSecret: ""
    existingSecretPasswordKey: ""
  
  # Resource configuration
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  
  # Persistence
  persistence:
    enabled: true
    storageClass: "standard"
    size: "8Gi"
    accessModes:
      - ReadWriteOnce
  
  # Configuration
  configuration: |
    # Network
    bind 0.0.0.0
    port 6379
    tcp-keepalive 300
    
    # Memory management
    maxmemory 400mb
    maxmemory-policy allkeys-lru
    
    # Persistence
    save 900 1
    save 300 10
    save 60 10000
    
    # Cluster
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 5000
    
    # Logging
    loglevel notice
    
    # Security
    protected-mode no

# Redis Sentinel Configuration
sentinel:
  enabled: true
  image:
    registry: docker.io
    repository: redis
    tag: "7.2.0-alpine"
  
  # Sentinel specific configuration
  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "128Mi"
      cpu: "100m"
  
  configuration: |
    port 26379
    sentinel monitor redis-master redis-node-0.redis.offerkiller-data.svc.cluster.local 6379 2
    sentinel down-after-milliseconds redis-master 5000
    sentinel parallel-syncs redis-master 1
    sentinel failover-timeout redis-master 10000

# Service configuration
service:
  type: ClusterIP
  port: 6379
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "6379"

# ServiceMonitor for Prometheus
serviceMonitor:
  enabled: true
  labels:
    app: redis-cluster
  interval: 30s
  path: /metrics

# Network Policy
networkPolicy:
  enabled: true
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: offerkiller-app
      - namespaceSelector:
          matchLabels:
            name: offerkiller-system
      ports:
      - protocol: TCP
        port: 6379
      - protocol: TCP
        port: 26379

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2

# Horizontal Pod Autoscaler
autoscaling:
  enabled: false
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Security Context
securityContext:
  runAsNonRoot: true
  runAsUser: 999
  fsGroup: 999

# Affinity and tolerations
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchLabels:
            app: redis-cluster
        topologyKey: kubernetes.io/hostname

# Additional labels
labels:
  app: redis-cluster
  version: "7.2.0"
  component: cache

# Backup configuration
backup:
  enabled: true
  schedule: "0 2 * * *"
  retention: "7d"
  storage:
    storageClass: "standard"
    size: "5Gi"
```

#### 5.1.2 Create RabbitMQ Cluster Helm Chart

**Create file: `E:\OfferKiller\infrastructure\helm\charts\rabbitmq-ha\Chart.yaml`**

```yaml
apiVersion: v2
name: rabbitmq-ha
description: High-availability RabbitMQ cluster for OfferKiller message broker
type: application
version: 1.0.0
appVersion: "3.12.0"
keywords:
  - rabbitmq
  - message broker
  - amqp
  - queue
home: https://rabbitmq.com/
sources:
  - https://github.com/rabbitmq/rabbitmq-server
maintainers:
  - name: OfferKiller Team
    email: devops@offerkiller.com
dependencies:
  - name: common
    repository: https://charts.bitnami.com/bitnami
    version: 2.x.x
annotations:
  category: Message Broker
  licenses: MPL-2.0
```

**Create file: `E:\OfferKiller\infrastructure\helm\charts\rabbitmq-ha\values.yaml`**

```yaml
# RabbitMQ HA Configuration
rabbitmq:
  image:
    registry: docker.io
    repository: rabbitmq
    tag: "3.12.0-management-alpine"
    pullPolicy: IfNotPresent
  
  # Cluster configuration
  clustering:
    enabled: true
    rebalance: true
    forceBoot: false
  
  # Authentication
  auth:
    username: "offerkilleruser"
    password: "rabbitmq123change"
    existingPasswordSecret: ""
    existingErlangSecret: ""
    erlangCookie: "offerkiller-rabbitmq-cookie-change-in-production"
  
  # Resource configuration
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  
  # Persistence
  persistence:
    enabled: true
    storageClass: "standard"
    size: "8Gi"
    accessModes:
      - ReadWriteOnce
  
  # Configuration
  configuration: |
    # Clustering
    cluster_formation.peer_discovery_backend = rabbit_peer_discovery_k8s
    cluster_formation.k8s.host = kubernetes.default.svc.cluster.local
    cluster_formation.k8s.address_type = hostname
    cluster_formation.node_cleanup.interval = 30
    cluster_formation.node_cleanup.only_log_warning = true
    cluster_partition_handling = autoheal
    
    # Queue management
    queue_master_locator = min-masters
    
    # Memory management
    vm_memory_high_watermark.relative = 0.6
    disk_free_limit.relative = 2.0
    
    # Networking
    listeners.tcp.default = 5672
    management.tcp.port = 15672
    
    # SSL/TLS
    listeners.ssl.default = 5671
    ssl_options.cacertfile = /opt/rabbitmq/ssl/ca_certificate.pem
    ssl_options.certfile = /opt/rabbitmq/ssl/server_certificate.pem
    ssl_options.keyfile = /opt/rabbitmq/ssl/server_key.pem
    ssl_options.verify = verify_peer
    ssl_options.fail_if_no_peer_cert = false
    
    # Logging
    log.file.level = info
    log.connection.level = info
    log.channel.level = info
    log.queue.level = info
    log.mirroring.level = info
    log.federation.level = info
    log.upgrade.level = info
    
    # Management plugin
    management.rates_mode = basic
    management.sample_retention_policies.global.minute = 5
    management.sample_retention_policies.global.hour = 60
    management.sample_retention_policies.global.day = 1440

# Load balancer configuration
loadBalancer:
  enabled: true
  port: 5672
  
# Service configuration
service:
  type: ClusterIP
  amqpPort: 5672
  amqpTlsPort: 5671
  managerPort: 15672
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "15692"
    prometheus.io/path: "/metrics"

# Ingress configuration
ingress:
  enabled: true
  ingressClassName: "istio"
  hostname: "rabbitmq.offerkiller.local"
  path: "/"
  tls: true
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /

# ServiceMonitor for Prometheus
serviceMonitor:
  enabled: true
  labels:
    app: rabbitmq-ha
  interval: 30s
  path: /metrics
  port: prometheus

# Plugins configuration
plugins:
  list: |
    rabbitmq_management
    rabbitmq_peer_discovery_k8s
    rabbitmq_prometheus
    rabbitmq_shovel
    rabbitmq_shovel_management
    rabbitmq_federation
    rabbitmq_federation_management

# Policies and definitions
policies:
  - name: "ha-policy"
    pattern: ".*"
    definition:
      ha-mode: "exactly"
      ha-params: 2
      ha-sync-mode: "automatic"
      ha-sync-batch-size: 1
      queue-master-locator: "min-masters"

# Network Policy
networkPolicy:
  enabled: true
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: offerkiller-app
      - namespaceSelector:
          matchLabels:
            name: offerkiller-system
      ports:
      - protocol: TCP
        port: 5672
      - protocol: TCP
        port: 5671
      - protocol: TCP
        port: 15672

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2

# Horizontal Pod Autoscaler
autoscaling:
  enabled: false
  minReplicas: 3
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Security Context
securityContext:
  runAsNonRoot: true
  runAsUser: 999
  fsGroup: 999

# Affinity and tolerations
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchLabels:
            app: rabbitmq-ha
        topologyKey: kubernetes.io/hostname

# Additional labels
labels:
  app: rabbitmq-ha
  version: "3.12.0"
  component: message-broker

# Backup configuration
backup:
  enabled: true
  schedule: "0 3 * * *"
  retention: "7d"
  storage:
    storageClass: "standard"
    size: "5Gi"

# Management UI configuration
management:
  enabled: true
  nodePort: 31672
  
# Monitoring and health checks
livenessProbe:
  enabled: true
  initialDelaySeconds: 60
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  enabled: true
  initialDelaySeconds: 20
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Replicas configuration
replicaCount: 3
```

#### 5.1.3 Create Vector Database Helm Chart

**Create file: `E:\OfferKiller\infrastructure\helm\charts\vector-database\Chart.yaml`**

```yaml
apiVersion: v2
name: vector-database
description: High-availability vector database cluster for OfferKiller AI operations
type: application
version: 1.0.0
appVersion: "0.4.0"
keywords:
  - vector
  - database
  - ai
  - ml
  - chroma
  - embeddings
home: https://www.trychroma.com/
sources:
  - https://github.com/chroma-core/chroma
maintainers:
  - name: OfferKiller Team
    email: devops@offerkiller.com
dependencies:
  - name: common
    repository: https://charts.bitnami.com/bitnami
    version: 2.x.x
annotations:
  category: Database
  licenses: Apache-2.0
```

**Create file: `E:\OfferKiller\infrastructure\helm\charts\vector-database\values.yaml`**

```yaml
# Vector Database Configuration
chromadb:
  image:
    registry: docker.io
    repository: chromadb/chroma
    tag: "0.4.15"
    pullPolicy: IfNotPresent
  
  # Authentication and security
  auth:
    enabled: true
    provider: "chromadb.auth.simple.SimpleAuthenticationServerProvider"
    credentials: "admin:vectordb123change"
  
  # Resource configuration
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  
  # Persistence configuration
  persistence:
    enabled: true
    storageClass: "standard"
    size: "50Gi"
    accessModes:
      - ReadWriteOnce
    mountPath: "/chroma/chroma"
  
  # Configuration
  configuration:
    host: "0.0.0.0"
    port: 8000
    cors_allow_origins: ["*"]
    log_level: "INFO"
    anonymized_telemetry: false
    
    # Storage backend
    chroma_db_impl: "chromadb.db.duckdb.DuckDB"
    chroma_server_nofile: 65535
    
    # Performance tuning
    max_batch_size: 5461
    chroma_segment_cache_policy: "LRU"
    chroma_segment_cache_size: 1000
    
    # API configuration
    chroma_server_grpc_port: 50051
    chroma_server_http_port: 8000
    
    # Backup and recovery
    chroma_sysdb_impl: "chromadb.sysdb.impl.sqlite.SqliteDB"
    chroma_producer_impl: "chromadb.ingest.impl.simple.SimpleProducer"
    chroma_consumer_impl: "chromadb.ingest.impl.simple.SimpleConsumer"

# Qdrant alternative configuration (optional)
qdrant:
  enabled: false
  image:
    registry: docker.io
    repository: qdrant/qdrant
    tag: "v1.6.0"
  
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  
  persistence:
    enabled: true
    storageClass: "standard"
    size: "20Gi"
    
  configuration:
    log_level: "INFO"
    storage:
      optimizers:
        deleted_threshold: 0.2
        vacuum_min_vector_number: 1000
        default_segment_number: 0
      wal:
        wal_capacity_mb: 32
        wal_segments_ahead: 0
      performance:
        max_search_threads: 0
        max_optimization_threads: 1

# Service configuration
service:
  type: ClusterIP
  chromaPort: 8000
  chromaGrpcPort: 50051
  qdrantPort: 6333
  qdrantGrpcPort: 6334
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8000"
    prometheus.io/path: "/api/v1/heartbeat"

# Ingress configuration
ingress:
  enabled: true
  ingressClassName: "istio"
  hostname: "vectordb.offerkiller.local"
  path: "/"
  tls: true
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /

# ServiceMonitor for Prometheus
serviceMonitor:
  enabled: true
  labels:
    app: vector-database
  interval: 30s
  path: /api/v1/heartbeat

# Network Policy
networkPolicy:
  enabled: true
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: offerkiller-app
      - namespaceSelector:
          matchLabels:
            name: offerkiller-system
      ports:
      - protocol: TCP
        port: 8000
      - protocol: TCP
        port: 50051
      - protocol: TCP
        port: 6333
      - protocol: TCP
        port: 6334

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Horizontal Pod Autoscaler
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Security Context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Affinity and tolerations
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchLabels:
            app: vector-database
        topologyKey: kubernetes.io/hostname

# Additional labels
labels:
  app: vector-database
  version: "0.4.15"
  component: vector-store

# Backup configuration
backup:
  enabled: true
  schedule: "0 4 * * *"
  retention: "14d"
  storage:
    storageClass: "standard"
    size: "10Gi"

# Health checks
livenessProbe:
  enabled: true
  httpGet:
    path: "/api/v1/heartbeat"
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  enabled: true
  httpGet:
    path: "/api/v1/heartbeat"
    port: 8000
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Init containers for data migration/setup
initContainers:
  - name: chroma-init
    image: busybox:1.35
    command:
      - sh
      - -c
      - |
        echo "Initializing ChromaDB storage..."
        mkdir -p /chroma/chroma
        chown -R 1000:1000 /chroma/chroma
        echo "Initialization complete"
    volumeMounts:
      - name: data
        mountPath: /chroma/chroma

# Collection management
collections:
  default:
    - name: "resumes"
      metadata:
        description: "Resume embeddings for similarity search"
        distance_function: "cosine"
    - name: "job_descriptions"
      metadata:
        description: "Job description embeddings for matching"
        distance_function: "cosine"
    - name: "skills"
      metadata:
        description: "Skill embeddings for gap analysis"
        distance_function: "cosine"
    - name: "interview_questions"
      metadata:
        description: "Interview question embeddings"
        distance_function: "cosine"

# Replicas configuration
replicaCount: 2
```

### 5.2 Windows: Create Environment-Specific Values Files

Now create the environment-specific configuration files:

#### 5.2.1 Development Environment Values

**Create file: `E:\OfferKiller\infrastructure\helm\values\development\redis-cluster.yaml`**

```yaml
# Redis Development Environment Configuration
redis:
  # Reduced resources for development
  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"
  
  # Smaller cluster for development
  cluster:
    nodes: 3
    replicas: 1
  
  # Reduced persistence
  persistence:
    size: "2Gi"
  
  # Development-specific configuration
  configuration: |
    bind 0.0.0.0
    port 6379
    maxmemory 200mb
    maxmemory-policy allkeys-lru
    save 300 10
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 5000
    loglevel notice
    protected-mode no

# Disable backup in development
backup:
  enabled: false

# Single replica for development
replicaCount: 3

# Development-specific labels
labels:
  environment: "development"
  app: redis-cluster
  version: "7.2.0"
```

**Create file: `E:\OfferKiller\infrastructure\helm\values\development\rabbitmq-ha.yaml`**

```yaml
# RabbitMQ Development Environment Configuration
rabbitmq:
  # Reduced resources for development
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  
  # Smaller persistence
  persistence:
    size: "4Gi"
  
  # Simplified configuration for development
  configuration: |
    cluster_formation.peer_discovery_backend = rabbit_peer_discovery_k8s
    cluster_formation.k8s.host = kubernetes.default.svc.cluster.local
    cluster_formation.k8s.address_type = hostname
    cluster_partition_handling = autoheal
    queue_master_locator = min-masters
    vm_memory_high_watermark.relative = 0.8
    disk_free_limit.relative = 1.0
    listeners.tcp.default = 5672
    management.tcp.port = 15672
    log.file.level = info
    management.rates_mode = basic

# Disable backup in development
backup:
  enabled: false

# Reduced replicas for development
replicaCount: 2

# Development-specific labels
labels:
  environment: "development"
  app: rabbitmq-ha
  version: "3.12.0"

# Simplified policies for development
policies:
  - name: "ha-policy-dev"
    pattern: ".*"
    definition:
      ha-mode: "exactly"
      ha-params: 1
      ha-sync-mode: "automatic"
```

**Create file: `E:\OfferKiller\infrastructure\helm\values\development\vector-database.yaml`**

```yaml
# Vector Database Development Environment Configuration
chromadb:
  # Reduced resources for development
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  
  # Smaller persistence
  persistence:
    size: "10Gi"
  
  # Development-specific configuration
  configuration:
    host: "0.0.0.0"
    port: 8000
    cors_allow_origins: ["*"]
    log_level: "DEBUG"
    anonymized_telemetry: false
    max_batch_size: 1000
    chroma_segment_cache_size: 100

# Disable Qdrant in development
qdrant:
  enabled: false

# Disable backup in development
backup:
  enabled: false

# Single replica for development
replicaCount: 1

# Development-specific labels
labels:
  environment: "development"
  app: vector-database
  version: "0.4.15"

# Simplified collections for development
collections:
  default:
    - name: "dev_resumes"
      metadata:
        description: "Development resume embeddings"
        distance_function: "cosine"
    - name: "dev_jobs"
      metadata:
        description: "Development job embeddings"
        distance_function: "cosine"
```

### 5.3 Windows: Create Deployment Scripts

#### 5.3.1 Create Windows PowerShell Deployment Script

**Create file: `E:\OfferKiller\scripts\deploy-data-layer.ps1`**

```powershell
# OfferKiller Data Layer Deployment Script
param(
    [Parameter(Mandatory=$false)]
    [ValidateSet("development", "staging", "production")]
    [string]$Environment = "development",
    
    [Parameter(Mandatory=$false)]
    [string]$KubeConfig = "",
    
    [Parameter(Mandatory=$false)]
    [switch]$DryRun = $false,
    
    [Parameter(Mandatory=$false)]
    [switch]$SkipRedis = $false,
    
    [Parameter(Mandatory=$false)]
    [switch]$SkipRabbitMQ = $false,
    
    [Parameter(Mandatory=$false)]
    [switch]$SkipVectorDB = $false,
    
    [Parameter(Mandatory=$false)]
    [switch]$Force = $false
)

Write-Host "🚀 OfferKiller Data Layer Deployment ($Environment)" -ForegroundColor Green
Write-Host "========================================================" -ForegroundColor Green

# Set kubeconfig if provided
if ($KubeConfig -ne "") {
    $env:KUBECONFIG = $KubeConfig
    Write-Host "📁 Using kubeconfig: $KubeConfig" -ForegroundColor Yellow
}

# Function to check prerequisites
function Test-Prerequisites {
    Write-Host "🔍 Checking prerequisites..." -ForegroundColor Cyan
    
    # Check kubectl
    try {
        kubectl version --client --short | Out-Null
        Write-Host "✅ kubectl is available" -ForegroundColor Green
    }
    catch {
        Write-Host "❌ kubectl is not available" -ForegroundColor Red
        return $false
    }
    
    # Check helm
    try {
        helm version --short | Out-Null
        Write-Host "✅ Helm is available" -ForegroundColor Green
    }
    catch {
        Write-Host "❌ Helm is not available" -ForegroundColor Red
        return $false
    }
    
    # Check cluster connectivity
    try {
        kubectl cluster-info | Out-Null
        Write-Host "✅ Cluster is accessible" -ForegroundColor Green
    }
    catch {
        Write-Host "❌ Cannot connect to cluster" -ForegroundColor Red
        return $false
    }
    
    # Check required namespaces
    $namespaces = @("offerkiller-data", "offerkiller-system")
    foreach ($ns in $namespaces) {
        $exists = kubectl get namespace $ns --ignore-not-found=true
        if (-not $exists) {
            Write-Host "📦 Creating namespace: $ns" -ForegroundColor Yellow
            if (-not $DryRun) {
                kubectl create namespace $ns
            }
        }
    }
    
    return $true
}

# Function to deploy Helm chart
function Deploy-HelmChart {
    param(
        [string]$ChartPath,
        [string]$ReleaseName,
        [string]$Namespace,
        [string]$ValuesFile,
        [string]$Description
    )
    
    Write-Host "📦 Deploying $Description..." -ForegroundColor Cyan
    
    $helmCmd = "helm upgrade --install $ReleaseName $ChartPath -n $Namespace --create-namespace"
    
    if ($ValuesFile -and (Test-Path $ValuesFile)) {
        $helmCmd += " -f $ValuesFile"
    }
    
    if ($DryRun) {
        $helmCmd += " --dry-run"
    } else {
        $helmCmd += " --wait --timeout 10m"
    }
    
    if ($Force) {
        $helmCmd += " --force"
    }
    
    Write-Host "🔧 Command: $helmCmd" -ForegroundColor Gray
    
    try {
        Invoke-Expression $helmCmd
        Write-Host "✅ $Description deployed successfully" -ForegroundColor Green
        return $true
    }
    catch {
        Write-Host "❌ Failed to deploy $Description" -ForegroundColor Red
        Write-Host $_.Exception.Message -ForegroundColor Red
        return $false
    }
}

# Function to wait for deployment
function Wait-ForDeployment {
    param(
        [string]$Namespace,
        [string]$DeploymentName,
        [int]$TimeoutSeconds = 300
    )
    
    if ($DryRun) {
        Write-Host "🏃 Skipping wait in dry run mode" -ForegroundColor Yellow
        return $true
    }
    
    Write-Host "⏳ Waiting for $DeploymentName to be ready..." -ForegroundColor Yellow
    
    $timeout = [datetime]::Now.AddSeconds($TimeoutSeconds)
    while ([datetime]::Now -lt $timeout) {
        try {
            $ready = kubectl get statefulset $DeploymentName -n $Namespace -o jsonpath='{.status.readyReplicas}' 2>$null
            $desired = kubectl get statefulset $DeploymentName -n $Namespace -o jsonpath='{.spec.replicas}' 2>$null
            
            if ($ready -eq $desired -and $ready -gt 0) {
                Write-Host "✅ $DeploymentName is ready!" -ForegroundColor Green
                return $true
            }
        }
        catch {
            # Deployment might not exist yet
        }
        
        Start-Sleep -Seconds 10
    }
    
    Write-Host "⚠️ Timeout waiting for $DeploymentName" -ForegroundColor Yellow
    return $false
}

# Function to verify services
function Test-Services {
    Write-Host "🔍 Verifying services..." -ForegroundColor Cyan
    
    if (-not $SkipRedis) {
        Write-Host "Testing Redis cluster..." -ForegroundColor Yellow
        $redisTest = kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli ping 2>$null
        if ($redisTest -eq "PONG") {
            Write-Host "✅ Redis cluster is responding" -ForegroundColor Green
        } else {
            Write-Host "⚠️ Redis cluster is not responding" -ForegroundColor Yellow
        }
    }
    
    if (-not $SkipRabbitMQ) {
        Write-Host "Testing RabbitMQ cluster..." -ForegroundColor Yellow
        $rmqTest = kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqctl cluster_status 2>$null
        if ($LASTEXITCODE -eq 0) {
            Write-Host "✅ RabbitMQ cluster is operational" -ForegroundColor Green
        } else {
            Write-Host "⚠️ RabbitMQ cluster has issues" -ForegroundColor Yellow
        }
    }
    
    if (-not $SkipVectorDB) {
        Write-Host "Testing Vector Database..." -ForegroundColor Yellow
        $vectorTest = kubectl exec -n offerkiller-data vector-database-0 -- curl -s http://localhost:8000/api/v1/heartbeat 2>$null
        if ($vectorTest) {
            Write-Host "✅ Vector Database is responding" -ForegroundColor Green
        } else {
            Write-Host "⚠️ Vector Database is not responding" -ForegroundColor Yellow
        }
    }
}

# Main deployment logic
if (-not (Test-Prerequisites)) {
    exit 1
}

# Navigate to project root
$ProjectRoot = Split-Path -Parent $PSScriptRoot
Set-Location $ProjectRoot

Write-Host "📂 Working directory: $PWD" -ForegroundColor Yellow
Write-Host "🎯 Target environment: $Environment" -ForegroundColor Yellow

# Deploy Redis Cluster
if (-not $SkipRedis) {
    $valuesFile = "infrastructure/helm/values/$Environment/redis-cluster.yaml"
    $success = Deploy-HelmChart -ChartPath "infrastructure/helm/charts/redis-cluster" `
                               -ReleaseName "redis-cluster" `
                               -Namespace "offerkiller-data" `
                               -ValuesFile $valuesFile `
                               -Description "Redis Cluster"
    
    if ($success) {
        Wait-ForDeployment -Namespace "offerkiller-data" -DeploymentName "redis-cluster"
    } else {
        Write-Host "❌ Redis deployment failed" -ForegroundColor Red
        exit 1
    }
}

# Deploy RabbitMQ Cluster
if (-not $SkipRabbitMQ) {
    $valuesFile = "infrastructure/helm/values/$Environment/rabbitmq-ha.yaml"
    $success = Deploy-HelmChart -ChartPath "infrastructure/helm/charts/rabbitmq-ha" `
                               -ReleaseName "rabbitmq-ha" `
                               -Namespace "offerkiller-data" `
                               -ValuesFile $valuesFile `
                               -Description "RabbitMQ HA Cluster"
    
    if ($success) {
        Wait-ForDeployment -Namespace "offerkiller-data" -DeploymentName "rabbitmq-ha"
    } else {
        Write-Host "❌ RabbitMQ deployment failed" -ForegroundColor Red
        exit 1
    }
}

# Deploy Vector Database
if (-not $SkipVectorDB) {
    $valuesFile = "infrastructure/helm/values/$Environment/vector-database.yaml"
    $success = Deploy-HelmChart -ChartPath "infrastructure/helm/charts/vector-database" `
                               -ReleaseName "vector-database" `
                               -Namespace "offerkiller-data" `
                               -ValuesFile $valuesFile `
                               -Description "Vector Database"
    
    if ($success) {
        Wait-ForDeployment -Namespace "offerkiller-data" -DeploymentName "vector-database"
    } else {
        Write-Host "❌ Vector Database deployment failed" -ForegroundColor Red
        exit 1
    }
}

# Verify deployments
Write-Host "`n🔍 Deployment Status:" -ForegroundColor Yellow
kubectl get pods -n offerkiller-data
kubectl get svc -n offerkiller-data
kubectl get pvc -n offerkiller-data

# Test services
Test-Services

Write-Host "`n🎉 Data layer deployment completed!" -ForegroundColor Green

# Get access information
if (-not $DryRun) {
    $minikubeIP = try { minikube ip } catch { "localhost" }
    
    Write-Host "`n📝 Access Information:" -ForegroundColor Yellow
    Write-Host "   Redis Cluster:     $minikubeIP:30379" -ForegroundColor Cyan
    Write-Host "   RabbitMQ Mgmt:     http://$minikubeIP:31672 (offerkilleruser/rabbitmq123change)" -ForegroundColor Cyan
    Write-Host "   Vector Database:   http://$minikubeIP:30800" -ForegroundColor Cyan
    
    Write-Host "`n🔧 Useful Commands:" -ForegroundColor Yellow
    Write-Host "   kubectl get pods -n offerkiller-data" -ForegroundColor White
    Write-Host "   kubectl logs -f statefulset/redis-cluster -n offerkiller-data" -ForegroundColor White
    Write-Host "   kubectl logs -f statefulset/rabbitmq-ha -n offerkiller-data" -ForegroundColor White
    Write-Host "   kubectl logs -f deployment/vector-database -n offerkiller-data" -ForegroundColor White
}

Write-Host "`n🚀 Ready for application deployment!" -ForegroundColor Green
```

### 5.4 Linux VM: Deploy the Data Layer Services

Now let's execute the deployment step by step:

#### 5.4.1 Copy Latest Code to Linux VM

**On Windows, commit and push the changes:**

```powershell
cd E:\OfferKiller

# Add all new files
git add .

# Commit the changes
git commit -m "Add Helm charts for Redis cluster, RabbitMQ HA, and Vector Database

- Complete Redis cluster configuration with Sentinel for HA
- RabbitMQ cluster with management UI and HA policies  
- ChromaDB vector database with backup and scaling
- Environment-specific values for dev/staging/prod
- Comprehensive deployment scripts for Windows and Linux
- Network policies and security configurations
- Monitoring and health check configurations"

# Push to GitHub
git push origin main
```

**On Linux VM, pull the latest changes:**

```bash
# SSH into your Linux VM
cd ~/offerkiller

# Pull latest changes
git pull origin main

# Make deployment scripts executable
chmod +x scripts/deploy-data-layer.sh
chmod +x infrastructure/helm/scripts/*.sh

# Verify Helm charts are present
ls -la infrastructure/helm/charts/
```

#### 5.4.2 Install Required Helm Repositories

```bash
# Add required Helm repositories for dependencies
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add stable https://charts.helm.sh/stable
helm repo update

# Verify repositories
helm repo list
```

#### 5.4.3 Create Namespace for Data Layer

```bash
# Create namespace for data layer services
kubectl create namespace offerkiller-data

# Label namespace for Istio injection
kubectl label namespace offerkiller-data istio-injection=enabled

# Verify namespace creation
kubectl get namespaces | grep offerkiller
```

#### 5.4.4 Deploy Redis Cluster

```bash
# Deploy Redis cluster first (since other services may depend on it)
helm upgrade --install redis-cluster \
  infrastructure/helm/charts/redis-cluster \
  -n offerkiller-data \
  -f infrastructure/helm/values/development/redis-cluster.yaml \
  --wait --timeout 10m

# Verify Redis deployment
kubectl get pods -n offerkiller-data | grep redis
kubectl get svc -n offerkiller-data | grep redis

# Wait for Redis to be ready
kubectl wait --for=condition=ready pod -l app=redis-cluster -n offerkiller-data --timeout=300s
```

#### 5.4.5 Test Redis Cluster

```bash
# Test Redis connectivity
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli ping

# Test cluster status
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli cluster info

# Test data persistence
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli set test-key "hello-world"
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli get test-key
```

#### 5.4.6 Deploy RabbitMQ HA Cluster

```bash
# Deploy RabbitMQ cluster
helm upgrade --install rabbitmq-ha \
  infrastructure/helm/charts/rabbitmq-ha \
  -n offerkiller-data \
  -f infrastructure/helm/values/development/rabbitmq-ha.yaml \
  --wait --timeout 10m

# Verify RabbitMQ deployment
kubectl get pods -n offerkiller-data | grep rabbitmq
kubectl get svc -n offerkiller-data | grep rabbitmq

# Wait for RabbitMQ to be ready
kubectl wait --for=condition=ready pod -l app=rabbitmq-ha -n offerkiller-data --timeout=300s
```

#### 5.4.7 Test RabbitMQ Cluster

```bash
# Test RabbitMQ cluster status
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqctl cluster_status

# Test management interface access
kubectl port-forward -n offerkiller-data svc/rabbitmq-ha 15672:15672 &

# In another terminal or use curl
curl -u offerkilleruser:rabbitmq123change http://localhost:15672/api/overview

# Test queue operations
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqadmin declare queue name=test-queue
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqadmin publish exchange=amq.default routing_key=test-queue payload="hello world"
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqadmin get queue=test-queue
```

#### 5.4.8 Deploy Vector Database

```bash
# Deploy Vector Database
helm upgrade --install vector-database \
  infrastructure/helm/charts/vector-database \
  -n offerkiller-data \
  -f infrastructure/helm/values/development/vector-database.yaml \
  --wait --timeout 10m

# Verify Vector Database deployment
kubectl get pods -n offerkiller-data | grep vector
kubectl get svc -n offerkiller-data | grep vector

# Wait for Vector Database to be ready
kubectl wait --for=condition=ready pod -l app=vector-database -n offerkiller-data --timeout=300s
```

#### 5.4.9 Test Vector Database

```bash
# Test ChromaDB API
kubectl exec -n offerkiller-data vector-database-0 -- curl -s http://localhost:8000/api/v1/heartbeat

# Test collection creation
kubectl port-forward -n offerkiller-data svc/vector-database 8000:8000 &

# Create test collection (in another terminal)
curl -X POST "http://localhost:8000/api/v1/collections" \
  -H "Content-Type: application/json" \
  -d '{"name": "test-collection", "metadata": {"description": "Test collection"}}'

# List collections
curl -X GET "http://localhost:8000/api/v1/collections"
```

### 5.5 Validation and Testing

#### 5.5.1 Comprehensive Service Health Check

```bash
# Create comprehensive health check script
cat > scripts/health-check-data-layer.sh << 'EOF'
#!/bin/bash

echo "🔍 OfferKiller Data Layer Health Check"
echo "======================================"

# Check namespace
echo "📦 Checking namespace..."
kubectl get namespace offerkiller-data

# Check all pods
echo "📋 Pod Status:"
kubectl get pods -n offerkiller-data -o wide

# Check services
echo "🌐 Service Status:"
kubectl get svc -n offerkiller-data

# Check persistent volumes
echo "💾 Storage Status:"
kubectl get pvc -n offerkiller-data

# Test Redis
echo "🔴 Testing Redis Cluster..."
redis_result=$(kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli ping 2>/dev/null)
if [ "$redis_result" = "PONG" ]; then
    echo "✅ Redis is responding"
    kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli cluster nodes | head -3
else
    echo "❌ Redis is not responding"
fi

# Test RabbitMQ
echo "🐰 Testing RabbitMQ Cluster..."
rabbitmq_result=$(kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqctl status --quiet 2>/dev/null)
if [ $? -eq 0 ]; then
    echo "✅ RabbitMQ is operational"
    kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqctl cluster_status --quiet | grep "Running nodes"
else
    echo "❌ RabbitMQ has issues"
fi

# Test Vector Database
echo "🧠 Testing Vector Database..."
vector_result=$(kubectl exec -n offerkiller-data vector-database-0 -- curl -s http://localhost:8000/api/v1/heartbeat 2>/dev/null)
if [ -n "$vector_result" ]; then
    echo "✅ Vector Database is responding"
    echo "Response: $vector_result"
else
    echo "❌ Vector Database is not responding"
fi

# Check resource usage
echo "📊 Resource Usage:"
kubectl top pods -n offerkiller-data 2>/dev/null || echo "Metrics server not available"

echo "✅ Health check completed!"
EOF

chmod +x scripts/health-check-data-layer.sh
./scripts/health-check-data-layer.sh
```

#### 5.5.2 Performance Testing

```bash
# Create performance test script for each service
cat > scripts/performance-test-data-layer.sh << 'EOF'
#!/bin/bash

echo "⚡ OfferKiller Data Layer Performance Tests"
echo "=========================================="

# Redis Performance Test
echo "🔴 Redis Performance Test..."
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli --latency-history -i 1 | head -10 &
redis_perf_pid=$!

kubectl exec -n offerkiller-data redis-cluster-0 -- redis-benchmark -t set,get -n 10000 -c 50 -d 64 --csv

kill $redis_perf_pid 2>/dev/null

# RabbitMQ Performance Test
echo "🐰 RabbitMQ Performance Test..."
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmq-perf-test -x 1 -y 2 -u "test-queue" -s 1000 -m 1000

# Vector Database Performance Test
echo "🧠 Vector Database Performance Test..."
kubectl port-forward -n offerkiller-data svc/vector-database 8000:8000 &
port_forward_pid=$!

sleep 5

# Simple API response time test
for i in {1..10}; do
    start_time=$(date +%s%N)
    curl -s http://localhost:8000/api/v1/heartbeat > /dev/null
    end_time=$(date +%s%N)
    response_time=$(( (end_time - start_time) / 1000000 ))
    echo "Vector DB Response $i: ${response_time}ms"
done

kill $port_forward_pid 2>/dev/null

echo "✅ Performance tests completed!"
EOF

chmod +x scripts/performance-test-data-layer.sh
```

#### 5.5.3 Integration Testing

```bash
# Create integration test script
cat > scripts/integration-test-data-layer.sh << 'EOF'
#!/bin/bash

echo "🔗 OfferKiller Data Layer Integration Tests"
echo "==========================================="

# Test cross-service connectivity
echo "📡 Testing service-to-service connectivity..."

# Test Redis from RabbitMQ pod
echo "Testing Redis from RabbitMQ pod..."
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- nc -zv redis-cluster.offerkiller-data.svc.cluster.local 6379

# Test Vector DB from Redis pod
echo "Testing Vector DB from Redis pod..."
kubectl exec -n offerkiller-data redis-cluster-0 -- nc -zv vector-database.offerkiller-data.svc.cluster.local 8000

# Test RabbitMQ from Vector DB pod
echo "Testing RabbitMQ from Vector DB pod..."
kubectl exec -n offerkiller-data vector-database-0 -- nc -zv rabbitmq-ha.offerkiller-data.svc.cluster.local 5672

# Test DNS resolution
echo "🌐 Testing DNS resolution..."
kubectl exec -n offerkiller-data redis-cluster-0 -- nslookup rabbitmq-ha.offerkiller-data.svc.cluster.local
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- nslookup vector-database.offerkiller-data.svc.cluster.local

# Test service discovery via Nacos
echo "🔍 Testing service registration with Nacos..."
nacos_url="http://nacos.offerkiller-system.svc.cluster.local:8848"
kubectl exec -n offerkiller-data redis-cluster-0 -- curl -s "$nacos_url/nacos/v1/ns/catalog/services"

echo "✅ Integration tests completed!"
EOF

chmod +x scripts/integration-test-data-layer.sh
./scripts/integration-test-data-layer.sh
```

### 5.6 Windows: Configure Access and Monitoring

#### 5.6.1 Configure Port Forwards for Development

**Create file: `E:\OfferKiller\scripts\setup-dev-access.ps1`**

```powershell
# OfferKiller Development Access Setup Script
Write-Host "🔗 Setting up development access to data layer services..." -ForegroundColor Green

# Function to start port forward in background
function Start-PortForward {
    param(
        [string]$Service,
        [string]$Namespace,
        [string]$LocalPort,
        [string]$RemotePort,
        [string]$Description
    )
    
    Write-Host "🚀 Starting port forward for $Description..." -ForegroundColor Cyan
    Write-Host "   Local: localhost:$LocalPort -> Remote: $Service:$RemotePort" -ForegroundColor Yellow
    
    $job = Start-Job -ScriptBlock {
        param($Service, $Namespace, $LocalPort, $RemotePort)
        kubectl port-forward -n $Namespace "svc/$Service" "${LocalPort}:${RemotePort}"
    } -ArgumentList $Service, $Namespace, $LocalPort, $RemotePort
    
    return $job
}

# Start port forwards
$jobs = @()

# Redis Cluster
$jobs += Start-PortForward -Service "redis-cluster" -Namespace "offerkiller-data" -LocalPort "6379" -RemotePort "6379" -Description "Redis Cluster"

# RabbitMQ Management
$jobs += Start-PortForward -Service "rabbitmq-ha" -Namespace "offerkiller-data" -LocalPort "15672" -RemotePort "15672" -Description "RabbitMQ Management UI"

# RabbitMQ AMQP
$jobs += Start-PortForward -Service "rabbitmq-ha" -Namespace "offerkiller-data" -LocalPort "5672" -RemotePort "5672" -Description "RabbitMQ AMQP"

# Vector Database
$jobs += Start-PortForward -Service "vector-database" -Namespace "offerkiller-data" -LocalPort "8000" -RemotePort "8000" -Description "Vector Database API"

Write-Host "`n✅ Port forwards started!" -ForegroundColor Green
Write-Host "`n📝 Access Information:" -ForegroundColor Yellow
Write-Host "   Redis:             localhost:6379" -ForegroundColor Cyan
Write-Host "   RabbitMQ AMQP:     localhost:5672" -ForegroundColor Cyan
Write-Host "   RabbitMQ Mgmt:     http://localhost:15672 (offerkilleruser/rabbitmq123change)" -ForegroundColor Cyan
Write-Host "   Vector Database:   http://localhost:8000" -ForegroundColor Cyan

Write-Host "`n🔧 Test Commands:" -ForegroundColor Yellow
Write-Host "   Redis:     redis-cli -h localhost -p 6379 ping" -ForegroundColor White
Write-Host "   RabbitMQ:  Open http://localhost:15672 in browser" -ForegroundColor White
Write-Host "   Vector:    curl http://localhost:8000/api/v1/heartbeat" -ForegroundColor White

Write-Host "`n⚠️  Press Ctrl+C to stop all port forwards" -ForegroundColor Yellow

# Wait for user input to stop
try {
    while ($true) {
        Start-Sleep -Seconds 5
        
        # Check if any jobs failed
        $failedJobs = $jobs | Where-Object { $_.State -eq "Failed" }
        if ($failedJobs) {
            Write-Host "⚠️ Some port forwards failed. Restarting..." -ForegroundColor Yellow
            $failedJobs | ForEach-Object { Remove-Job $_ -Force }
            # Restart logic could be added here
        }
    }
}
finally {
    Write-Host "`n🛑 Stopping all port forwards..." -ForegroundColor Yellow
    $jobs | ForEach-Object { Stop-Job $_ -Force; Remove-Job $_ -Force }
    Write-Host "✅ All port forwards stopped." -ForegroundColor Green
}
```

#### 5.6.2 Create Monitoring Dashboard Configuration

**Create file: `E:\OfferKiller\infrastructure\monitoring\grafana\dashboards\data-layer-dashboard.json`**

```json
{
  "dashboard": {
    "id": null,
    "title": "OfferKiller Data Layer Dashboard",
    "tags": ["offerkiller", "data-layer", "redis", "rabbitmq", "vector-db"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Redis Cluster Status",
        "type": "stat",
        "targets": [
          {
            "expr": "redis_connected_clients",
            "legendFormat": "Connected Clients"
          },
          {
            "expr": "redis_keyspace_hits_total",
            "legendFormat": "Cache Hits"
          },
          {
            "expr": "redis_keyspace_misses_total", 
            "legendFormat": "Cache Misses"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "RabbitMQ Cluster Status",
        "type": "stat",
        "targets": [
          {
            "expr": "rabbitmq_global_messages_ready",
            "legendFormat": "Messages Ready"
          },
          {
            "expr": "rabbitmq_global_messages_unacknowledged",
            "legendFormat": "Unacked Messages"
          },
          {
            "expr": "rabbitmq_connections",
            "legendFormat": "Connections"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "Vector Database Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(chromadb_requests_total[5m])",
            "legendFormat": "Requests/sec"
          },
          {
            "expr": "chromadb_request_duration_seconds",
            "legendFormat": "Response Time"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

### 5.7 Create Backup and Recovery Procedures

#### 5.7.1 Create Backup Script

**Create file: `E:\OfferKiller\scripts\backup-data-layer.sh`**

```bash
#!/bin/bash

# OfferKiller Data Layer Backup Script

set -e

BACKUP_DATE=$(date +"%Y%m%d_%H%M%S")
BACKUP_DIR="/tmp/offerkiller-backups/$BACKUP_DATE"
NAMESPACE="offerkiller-data"

echo "📦 OfferKiller Data Layer Backup - $BACKUP_DATE"
echo "==============================================="

# Create backup directory
mkdir -p "$BACKUP_DIR"

# Function to backup Redis
backup_redis() {
    echo "🔴 Backing up Redis cluster..."
    
    # Create Redis dump
    kubectl exec -n $NAMESPACE redis-cluster-0 -- redis-cli BGSAVE
    
    # Wait for backup to complete
    while [ "$(kubectl exec -n $NAMESPACE redis-cluster-0 -- redis-cli LASTSAVE)" = "$(kubectl exec -n $NAMESPACE redis-cluster-0 -- redis-cli LASTSAVE)" ]; do
        sleep 1
    done
    
    # Copy dump file
    kubectl cp $NAMESPACE/redis-cluster-0:/data/dump.rdb "$BACKUP_DIR/redis-dump.rdb"
    
    # Export cluster configuration
    kubectl get configmap redis-cluster-config -n $NAMESPACE -o yaml > "$BACKUP_DIR/redis-config.yaml"
    
    echo "✅ Redis backup completed"
}

# Function to backup RabbitMQ
backup_rabbitmq() {
    echo "🐰 Backing up RabbitMQ cluster..."
    
    # Export definitions
    kubectl exec -n $NAMESPACE rabbitmq-ha-0 -- rabbitmqctl export_definitions /tmp/rabbitmq-definitions.json
    kubectl cp $NAMESPACE/rabbitmq-ha-0:/tmp/rabbitmq-definitions.json "$BACKUP_DIR/rabbitmq-definitions.json"
    
    # Backup persistent data
    kubectl exec -n $NAMESPACE rabbitmq-ha-0 -- tar -czf /tmp/rabbitmq-data.tar.gz /var/lib/rabbitmq/
    kubectl cp $NAMESPACE/rabbitmq-ha-0:/tmp/rabbitmq-data.tar.gz "$BACKUP_DIR/rabbitmq-data.tar.gz"
    
    # Export configuration
    kubectl get configmap rabbitmq-ha-config -n $NAMESPACE -o yaml > "$BACKUP_DIR/rabbitmq-config.yaml"
    
    echo "✅ RabbitMQ backup completed"
}

# Function to backup Vector Database
backup_vector_database() {
    echo "🧠 Backing up Vector Database..."
    
    # Backup ChromaDB data
    kubectl exec -n $NAMESPACE vector-database-0 -- tar -czf /tmp/chromadb-data.tar.gz /chroma/chroma/
    kubectl cp $NAMESPACE/vector-database-0:/tmp/chromadb-data.tar.gz "$BACKUP_DIR/chromadb-data.tar.gz"
    
    # Export collections metadata
    kubectl port-forward -n $NAMESPACE svc/vector-database 8000:8000 &
    port_forward_pid=$!
    
    sleep 5
    
    # Export collections list
    curl -s http://localhost:8000/api/v1/collections > "$BACKUP_DIR/chromadb-collections.json"
    
    kill $port_forward_pid 2>/dev/null
    
    # Export configuration
    kubectl get configmap vector-database-config -n $NAMESPACE -o yaml > "$BACKUP_DIR/vector-database-config.yaml"
    
    echo "✅ Vector Database backup completed"
}

# Function to backup Kubernetes resources
backup_kubernetes_resources() {
    echo "☸️ Backing up Kubernetes resources..."
    
    # Backup all resources in the namespace
    kubectl get all -n $NAMESPACE -o yaml > "$BACKUP_DIR/kubernetes-resources.yaml"
    kubectl get pvc -n $NAMESPACE -o yaml > "$BACKUP_DIR/persistent-volume-claims.yaml"
    kubectl get secrets -n $NAMESPACE -o yaml > "$BACKUP_DIR/secrets.yaml"
    kubectl get configmaps -n $NAMESPACE -o yaml > "$BACKUP_DIR/configmaps.yaml"
    
    echo "✅ Kubernetes resources backup completed"
}

# Execute backups
backup_redis
backup_rabbitmq
backup_vector_database
backup_kubernetes_resources

# Create backup metadata
cat > "$BACKUP_DIR/backup-metadata.json" << EOF
{
  "backup_date": "$BACKUP_DATE",
  "namespace": "$NAMESPACE",
  "services": ["redis-cluster", "rabbitmq-ha", "vector-database"],
  "backup_size": "$(du -sh $BACKUP_DIR | cut -f1)",
  "kubernetes_version": "$(kubectl version --short --client)",
  "cluster_info": "$(kubectl cluster-info | head -1)"
}
EOF

# Compress backup
tar -czf "/tmp/offerkiller-backup-$BACKUP_DATE.tar.gz" -C "/tmp/offerkiller-backups" "$BACKUP_DATE"

echo "📦 Backup completed: /tmp/offerkiller-backup-$BACKUP_DATE.tar.gz"
echo "📊 Backup size: $(du -sh /tmp/offerkiller-backup-$BACKUP_DATE.tar.gz | cut -f1)"

# Cleanup temporary directory
rm -rf "$BACKUP_DIR"

echo "✅ Backup process completed successfully!"
```

### 5.8 Troubleshooting Guide

#### 5.8.1 Common Issues and Solutions

**Create file: `E:\OfferKiller\docs\troubleshooting\data-layer-issues.md`**

```markdown
# Data Layer Troubleshooting Guide

## Common Issues and Solutions

### 1. Redis Cluster Issues

#### Problem: Redis nodes cannot form cluster
```bash
kubectl logs -n offerkiller-data redis-cluster-0
```

**Solution**: Check network policies and ensure nodes can communicate
```bash
# Check network connectivity between nodes
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli -h redis-cluster-1.redis-cluster 6379 ping

# Reset cluster if needed
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli FLUSHALL
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli CLUSTER RESET
```

#### Problem: Redis memory issues
```bash
kubectl top pods -n offerkiller-data | grep redis
```

**Solution**: Adjust memory limits and configuration
```bash
# Check memory usage
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli INFO memory

# Update resource limits
kubectl patch statefulset redis-cluster -n offerkiller-data -p '{"spec":{"template":{"spec":{"containers":[{"name":"redis","resources":{"limits":{"memory":"1Gi"}}}]}}}}'
```

### 2. RabbitMQ Cluster Issues

#### Problem: RabbitMQ cluster split-brain
```bash
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqctl cluster_status
```

**Solution**: Force cluster reformation
```bash
# Stop all nodes except one
kubectl scale statefulset rabbitmq-ha -n offerkiller-data --replicas=1

# Wait for single node to be ready
kubectl wait --for=condition=ready pod rabbitmq-ha-0 -n offerkiller-data --timeout=300s

# Scale back up
kubectl scale statefulset rabbitmq-ha -n offerkiller-data --replicas=3
```

#### Problem: RabbitMQ management UI not accessible
```bash
kubectl get svc -n offerkiller-data | grep rabbitmq
```

**Solution**: Check service configuration and port forwards
```bash
# Check service endpoints
kubectl get endpoints rabbitmq-ha -n offerkiller-data

# Test management plugin
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmq-plugins list | grep management

# Enable management plugin if needed
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmq-plugins enable rabbitmq_management
```

### 3. Vector Database Issues

#### Problem: ChromaDB not responding
```bash
kubectl logs -n offerkiller-data vector-database-0
```

**Solution**: Check storage and restart if needed
```bash
# Check disk space
kubectl exec -n offerkiller-data vector-database-0 -- df -h

# Check ChromaDB process
kubectl exec -n offerkiller-data vector-database-0 -- ps aux | grep chroma

# Restart if needed
kubectl rollout restart deployment/vector-database -n offerkiller-data
```

#### Problem: Vector collections not accessible
```bash
curl -X GET "http://localhost:8000/api/v1/collections"
```

**Solution**: Verify data persistence and reinitialize collections
```bash
# Check persistent volume
kubectl get pvc -n offerkiller-data | grep vector

# Check data directory
kubectl exec -n offerkiller-data vector-database-0 -- ls -la /chroma/chroma/

# Recreate collections if needed
curl -X POST "http://localhost:8000/api/v1/collections" \
  -H "Content-Type: application/json" \
  -d '{"name": "resumes", "metadata": {"description": "Resume embeddings"}}'
```

### 4. Storage Issues

#### Problem: Persistent volumes not mounting
```bash
kubectl get pvc -n offerkiller-data
kubectl describe pvc redis-cluster-data-redis-cluster-0 -n offerkiller-data
```

**Solution**: Check storage class and provisioner
```bash
# Check storage class
kubectl get storageclass

# Check provisioner
kubectl get pods -n kube-system | grep provisioner

# Recreate PVC if needed
kubectl delete pvc redis-cluster-data-redis-cluster-0 -n offerkiller-data
kubectl patch statefulset redis-cluster -n offerkiller-data -p '{"spec":{"volumeClaimTemplates":[{"metadata":{"name":"data"},"spec":{"storageClassName":"standard","accessModes":["ReadWriteOnce"],"resources":{"requests":{"storage":"8Gi"}}}}]}}'
```

### 5. Network and Connectivity Issues

#### Problem: Services cannot reach each other
```bash
kubectl get networkpolicy -n offerkiller-data
```

**Solution**: Review and adjust network policies
```bash
# Test connectivity
kubectl exec -n offerkiller-data redis-cluster-0 -- nc -zv rabbitmq-ha.offerkiller-data.svc.cluster.local 5672

# Temporarily disable network policies for testing
kubectl delete networkpolicy --all -n offerkiller-data

# Check DNS resolution
kubectl exec -n offerkiller-data redis-cluster-0 -- nslookup vector-database.offerkiller-data.svc.cluster.local
```

### 6. Performance Issues

#### Problem: High latency or poor performance
```bash
kubectl top pods -n offerkiller-data
kubectl top nodes
```

**Solution**: Scale resources and optimize configuration
```bash
# Scale up resources
kubectl patch statefulset redis-cluster -n offerkiller-data -p '{"spec":{"template":{"spec":{"containers":[{"name":"redis","resources":{"requests":{"cpu":"500m","memory":"512Mi"},"limits":{"cpu":"1000m","memory":"1Gi"}}}]}}}}'

# Enable HPA for auto-scaling
kubectl autoscale deployment vector-database -n offerkiller-data --cpu-percent=70 --min=2 --max=5
```

## Diagnostic Commands

### General Health Check
```bash
# Overall status
kubectl get all -n offerkiller-data

# Resource usage
kubectl top pods -n offerkiller-data

# Events
kubectl get events -n offerkiller-data --sort-by=.metadata.creationTimestamp
```

### Service-Specific Diagnostics
```bash
# Redis diagnostics
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli INFO
kubectl exec -n offerkiller-data redis-cluster-0 -- redis-cli CLUSTER NODES

# RabbitMQ diagnostics
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqctl status
kubectl exec -n offerkiller-data rabbitmq-ha-0 -- rabbitmqctl cluster_status

# Vector Database diagnostics
kubectl exec -n offerkiller-data vector-database-0 -- curl -s http://localhost:8000/api/v1/heartbeat
kubectl logs -n offerkiller-data vector-database-0 --tail=100
```

### Log Analysis
```bash
# Tail logs for all services
kubectl logs -f statefulset/redis-cluster -n offerkiller-data
kubectl logs -f statefulset/rabbitmq-ha -n offerkiller-data
kubectl logs -f deployment/vector-database -n offerkiller-data

# Search for errors
kubectl logs statefulset/redis-cluster -n offerkiller-data | grep -i error
kubectl logs statefulset/rabbitmq-ha -n offerkiller-data | grep -i error
```

## Recovery Procedures

### Complete Reset
```bash
# Delete all resources
helm uninstall redis-cluster -n offerkiller-data
helm uninstall rabbitmq-ha -n offerkiller-data
helm uninstall vector-database -n offerkiller-data

# Clean up persistent data
kubectl delete pvc --all -n offerkiller-data

# Redeploy
./scripts/deploy-data-layer.sh --environment development
```

### Backup and Restore
```bash
# Create backup
./scripts/backup-data-layer.sh

# Restore from backup
./scripts/restore-data-layer.sh /path/to/backup.tar.gz
```
```

## Success Criteria

Your Step 5 implementation is **successful** when you can confirm:

### ✅ **Redis Cluster Operational**
- [ ] Redis cluster with multiple nodes running and healthy
- [ ] Redis Sentinel monitoring and failover capability
- [ ] Cache operations working (SET/GET commands)
- [ ] Cluster status shows all nodes connected
- [ ] Performance metrics being collected

### ✅ **RabbitMQ HA Cluster Functional**
- [ ] RabbitMQ cluster with HA policies configured
- [ ] Management UI accessible and functional
- [ ] Queue operations working (publish/consume)
- [ ] Cluster status shows all nodes joined
- [ ] Message persistence enabled

### ✅ **Vector Database Ready**
- [ ] ChromaDB instance running and accessible
- [ ] API endpoints responding correctly
- [ ] Collections can be created and queried
- [ ] Persistent storage mounted and working
- [ ] Health checks passing

### ✅ **High Availability Configured**
- [ ] Pod disruption budgets in place
- [ ] Anti-affinity rules distributing pods across nodes
- [ ] Persistent volumes for data durability
- [ ] Backup procedures tested and working
- [ ] Monitoring and alerting configured

### ✅ **Integration Ready**
- [ ] Services discoverable via DNS
- [ ] Network policies allowing appropriate traffic
- [ ] Service mesh integration (Istio) functional
- [ ] Connection from application namespace tested
- [ ] Configuration management via Nacos prepared

**Test Command to Verify Success:**
```bash
# Run comprehensive verification
./scripts/health-check-data-layer.sh && \
./scripts/integration-test-data-layer.sh && \
echo "✅ Data layer is ready for application integration!"
```

## Next Steps

After completing Step 5 successfully:

1. **✅ Step 1**: Docker development environment ✓
2. **✅ Step 2**: Git monorepo structure ✓  
3. **✅ Step 3**: GitHub Actions CI/CD pipeline ✓
4. **✅ Step 4**: Kubernetes foundational services ✓
5. **✅ Step 5**: Helm-deployed data layer services ✓
6. **➡️ Step 6**: MySQL database schemas and MyBatis data access layer

You now have a **complete high-availability data infrastructure** providing:
- **Distributed Caching**: Redis cluster for session storage and temporary data
- **Reliable Messaging**: RabbitMQ cluster for asynchronous communication
- **AI Vector Operations**: ChromaDB for embeddings and similarity search
- **Enterprise Features**: Backup, monitoring, scaling, and recovery capabilities
- **Production Readiness**: HA configuration with fault tolerance

Your microservices can now leverage this robust data layer for scalable, reliable operations!

## Notes for User Actions

### 🖥️ **Windows Tasks for You:**
1. **Review Configuration Files**: Check all Helm values files in `infrastructure/helm/values/`
2. **Test Development Access**: Run `scripts/setup-dev-access.ps1` to access services locally
3. **Verify Integration**: Ensure your development tools can connect to the data layer services

### 🐧 **Linux Tasks for You:**
1. **Execute Deployment**: Run `./scripts/deploy-data-layer.sh --environment development`
2. **Run Health Checks**: Execute `./scripts/health-check-data-layer.sh`
3. **Performance Testing**: Run `./scripts/performance-test-data-layer.sh`
4. **Create Backup**: Execute `./scripts/backup-data-layer.sh`

### 🔧 **Configuration Tasks:**
1. **Update Passwords**: Change default passwords in values files before production
2. **Resource Tuning**: Adjust CPU/memory based on your VM capacity
3. **Storage Configuration**: Verify storage classes match your cluster setup
4. **Monitoring Setup**: Configure Grafana dashboards for data layer monitoring

The data layer is now ready to support all OfferKiller applications with enterprise-grade reliability and performance!
